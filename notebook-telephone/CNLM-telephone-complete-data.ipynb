{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions_NLM import estimate_nested_logit, simulate_choice\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> CNLM with alpha as variable </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log-likelihood function for telephone data\n",
    "# beta will be beta = [\"ASC_1\", \"ASC_3\", \"ASC_4\", \"ASC_5\",\n",
    "#                       \"BETA_COST\", \"lambda_measured\", \"lambda_flat\", \"alpha_3_with_measured\"]\n",
    "\n",
    "# before [\"ASC_CAR\", \"ASC_SM\", \"BETA_TT\", \"BETA_TC\", \"lambda_CAR_TRAIN\", \"lambda_SM_TRAIN\", \"base_alpha_TRAIN_WITH_CAR\"]\n",
    "\n",
    "# DEFINE MODEL STRUCTURE AND LIKELIHOOD FUNCTION\n",
    "def log_likelihood_telephone_CNLM(beta, data):\n",
    "    alpha_3_with_measured = np.exp(beta[7]) / (1 + np.exp(beta[7]))\n",
    "    alpha_3_with_flat = 1 - alpha_3_with_measured \n",
    "    # alpha_3_with_measured should be between 0 and 1\n",
    "    if alpha_3_with_measured < 0: \n",
    "        alpha_3_with_measured = 0\n",
    "\n",
    "    if alpha_3_with_measured > 1: \n",
    "        alpha_3_with_measured = 1\n",
    "\n",
    "            \n",
    "    # Define utility functions\n",
    "    data['U_1'] = beta[0] + beta[4] * data['logcost1']\n",
    "    data['U_2'] = beta[4] * data['logcost2']\n",
    "    data['U_3'] = beta[1] + beta[4] * data['logcost3']\n",
    "    data['U_4'] = beta[2] + beta[4] * data['logcost4']\n",
    "    data['U_5'] = beta[3] + beta[4] * data['logcost5']\n",
    "\n",
    "    # combined utility terms inside nests\n",
    "    data['log_U_measured_3'] = np.log((alpha_3_with_measured * data['avail3'] * np.exp(data['U_3'])) ** (1 / beta[5]) + \\\n",
    "                             data['avail1'] * np.exp(data['U_1']) ** (1 / beta[5]) + \\\n",
    "                             data['avail2'] * np.exp(data['U_2']) ** (1 / beta[5]))\n",
    "    data['log_U_flat_3'] = np.log((alpha_3_with_flat * data['avail3'] * np.exp(data['U_3'])) ** (1 / beta[6]) + \\\n",
    "                            data['avail4'] * np.exp(data['U_4']) ** (1 / beta[6]) + \\\n",
    "                            data['avail5'] * np.exp(data['U_5']) ** (1 / beta[6]))\n",
    "\n",
    "    # Nest probabilities\n",
    "    data['log_P_nest_measured_3'] = data['log_U_measured_3'] * beta[5] - \\\n",
    "                                np.log(np.exp(data['log_U_measured_3']) ** beta[5] + \\\n",
    "                                       np.exp(data['log_U_flat_3']) ** beta[6])\n",
    "    data['log_P_nest_flat_3'] = np.log(1 - np.exp(data['log_P_nest_measured_3']))\n",
    "\n",
    "    # Within nest probabilities\n",
    "    data['log_P_1_in_measured_3'] = np.log(data['avail1']) + data['U_1'] / beta[5] - data['log_U_measured_3']\n",
    "    data['log_P_3_in_measured_3'] = (np.log(data['avail3']) + np.log(alpha_3_with_measured) + \\\n",
    "                                     data['U_3']) / beta[5] - data['log_U_measured_3']\n",
    "    data['log_P_2_in_measured_3'] = np.log(1 - np.exp(data['log_P_1_in_measured_3']) - \\\n",
    "                                           np.exp(data['log_P_3_in_measured_3']))\n",
    "    data['log_P_4_in_flat_3'] = np.where(data['avail4'] == 0, -np.inf,\n",
    "                                     np.log(data['avail4']) + data['U_4'] / beta[6] - data['log_U_flat_3'])\n",
    "    data['log_P_3_in_flat_3'] = (np.log(data['avail3']) + np.log(alpha_3_with_flat) + \\\n",
    "                                 data['U_3']) / beta[6] - data['log_U_flat_3']\n",
    "    data['log_P_5_in_flat_3'] = np.where(data['avail5'] == 0, -np.inf, \n",
    "                                         np.log(1 - np.exp(data['log_P_4_in_flat_3']) - \\\n",
    "                                                np.exp(data['log_P_3_in_flat_3'])))\n",
    "\n",
    "    # Full probabilities\n",
    "    data['P_1'] = np.exp(data['log_P_nest_measured_3'] + data['log_P_1_in_measured_3'])\n",
    "    data['P_2'] = np.exp(data['log_P_nest_measured_3'] + data['log_P_2_in_measured_3'])\n",
    "    data['P_3'] = np.exp(data['log_P_nest_measured_3'] + data['log_P_3_in_measured_3']) + \\\n",
    "                np.exp(data['log_P_nest_flat_3'] + data['log_P_3_in_flat_3'])\n",
    "    data['P_4'] = np.exp(data['log_P_nest_flat_3'] + data['log_P_4_in_flat_3'])\n",
    "    data['P_5'] = np.exp(data['log_P_nest_flat_3'] + data['log_P_5_in_flat_3'])\n",
    "\n",
    "    # Calculate probability for chosen alternative for each row\n",
    "    data['P'] = (data['choice'] == 1) * data['P_1'] + \\\n",
    "                (data['choice'] == 2) * data['P_2'] + \\\n",
    "                (data['choice'] == 3) * data['P_3'] + \\\n",
    "                (data['choice'] == 4) * data['P_4'] + \\\n",
    "                (data['choice'] == 5) * data['P_5']\n",
    "\n",
    "    # Calculate log-likelihood \n",
    "    LL = data['P'].apply(np.log).sum()\n",
    "\n",
    "    return -LL  # We minimize negative log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('../data/telephone.dat', sep='\\t')\n",
    "\n",
    "data['logcost1'] = np.log(data['cost1'])\n",
    "data['logcost2'] = np.log(data['cost2'])\n",
    "data['logcost3'] = np.log(data['cost3'])\n",
    "data['logcost4'] = np.log(data['cost4'])\n",
    "data['logcost5'] = np.log(data['cost5'])\n",
    "\n",
    "# Define model parameters\n",
    "beta = np.array([0, 0, 0, 0, 0, 1, 1, 0])\n",
    "# lambda_n = 1 / mu_n is a measure of the degree of independence in unobserved utility among\n",
    "# the alternatives in nest n.\n",
    "# It should be between 0 and 1 with lambda_n = 1 indicating full independence.\n",
    "beta_names = [\"ASC_1\", \"ASC_3\", \"ASC_4\", \"ASC_5\", \"BETA_COST\", \"lambda_measured\", \"lambda_flat\", \"alpha_3_with_measured\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import t\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â We have to change the function estimate_nested_logit because we have to add bounds for alpha_3_with_measured\n",
    "def estimate_nested_logit_CNLM(data, beta_initial, beta_names, log_likelihood_function):\n",
    "    \"\"\"\n",
    "    Estimate parameters for a nested logit model using maximum likelihood estimation.\n",
    "\n",
    "    Args:\n",
    "    - data (DataFrame): Input dataset containing variables needed for the model.\n",
    "    - beta_initial (array-like): Initial guess for model parameters.\n",
    "    - beta_names (list): Names of model parameters.\n",
    "    - log_likelihood_function (function): Function that calculates the log-likelihood of the model. \n",
    "\n",
    "    Returns:\n",
    "    - result (OptimizeResult): Result object from scipy.optimize.minimize containing optimization results.\n",
    "    - se (array-like): Robust asymptotic standard errors of parameter estimates.\n",
    "    - t_stat (array-like): t-statistics of parameter estimates.\n",
    "    - p_value (array-like): p-values of parameter estimates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Run the model\n",
    "    result = minimize(log_likelihood_function, x0 = beta_initial, args = data, method='L-BFGS-B',\n",
    "    bounds = ((None, None), (None, None), (None, None), (None, None), (None, None), (None, None),\n",
    "               (None, None), (0, 1)))\n",
    "\n",
    "    # Calculate Hessian matrix\n",
    "    hessian_inv = result.hess_inv.todense()\n",
    "\n",
    "    # Calculate robust asymptotic standard errors\n",
    "    se = np.sqrt(np.diag(hessian_inv))\n",
    "\n",
    "    # Calculate t-statistics\n",
    "    t_stat = result.x / se\n",
    "\n",
    "    # Calculate p-values\n",
    "    p_value = (1 - t.cdf(np.abs(t_stat), len(data) - len(beta_initial))) * 2\n",
    "\n",
    "    # Calculate AIC\n",
    "    log_likelihood_value = -result.fun\n",
    "    k = len(beta_initial)\n",
    "    n = len(data)\n",
    "    aic = 2 * k - 2 * log_likelihood_value\n",
    "\n",
    "    # Calculate BIC\n",
    "    bic = np.log(n) * k - 2 * log_likelihood_value\n",
    "\n",
    "    # Create DataFrame to store results\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Parameter\": beta_names,\n",
    "        \"Estimate\": result.x,\n",
    "        \"Robust Asymptotic SE\": se,\n",
    "        \"t-statistic\": t_stat,\n",
    "        \"p-value\": p_value\n",
    "    })\n",
    "\n",
    "    print(\"Optimization Results:\")\n",
    "    print(results_df)\n",
    "    print(\"AIC:\", aic)\n",
    "    print(\"BIC:\", bic)\n",
    "\n",
    "    return result, se, t_stat, p_value, aic, bic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Results:\n",
      "               Parameter  Estimate  Robust Asymptotic SE  t-statistic  \\\n",
      "0                  ASC_1 -1.426263              0.501990    -2.841216   \n",
      "1                  ASC_3  2.003235              0.506590     3.954352   \n",
      "2                  ASC_4  2.147718              3.059635     0.701952   \n",
      "3                  ASC_5  3.740691              1.470948     2.543048   \n",
      "4              BETA_COST -3.198239              0.876837    -3.647473   \n",
      "5        lambda_measured  2.172737              0.729996     2.976370   \n",
      "6            lambda_flat  1.894093              2.576903     0.735027   \n",
      "7  alpha_3_with_measured  1.000000              1.000000     1.000000   \n",
      "\n",
      "    p-value  \n",
      "0  0.004710  \n",
      "1  0.000090  \n",
      "2  0.483092  \n",
      "3  0.011342  \n",
      "4  0.000298  \n",
      "5  0.003083  \n",
      "6  0.462728  \n",
      "7  0.317878  \n",
      "AIC: 962.6011872954471\n",
      "BIC: 995.1855435682503\n"
     ]
    }
   ],
   "source": [
    "# Estimate parameters\n",
    "result, se, t_stat, p_value, aic, bic  = estimate_nested_logit_CNLM(data, beta,\n",
    "                                                                     beta_names, log_likelihood_telephone_CNLM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> CNLM with fixed alpha </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log-likelihood function for telephone data\n",
    "# beta will be beta = [\"ASC_1\", \"ASC_3\", \"ASC_4\", \"ASC_5\",\n",
    "#                       \"BETA_COST\", \"lambda_measured\", \"lambda_flat\"]\n",
    "\n",
    "\n",
    "# DEFINE LIKELIHOOD FUNCTION\n",
    "def log_likelihood_telephone_CNLM2(beta, data):\n",
    "    alpha_3_with_measured = 0.5\n",
    "    alpha_3_with_flat = 1 - alpha_3_with_measured\n",
    "\n",
    "    # Define utility functions\n",
    "    data['U_1'] = beta[0] + beta[4] * data['logcost1']\n",
    "    data['U_2'] = beta[4] * data['logcost2']\n",
    "    data['U_3'] = beta[1] + beta[4] * data['logcost3']\n",
    "    data['U_4'] = beta[2] + beta[4] * data['logcost4']\n",
    "    data['U_5'] = beta[3] + beta[4] * data['logcost5']\n",
    "\n",
    "    # combined utility terms inside nests\n",
    "    data['log_U_measured_3'] = np.log((alpha_3_with_measured * data['avail3'] * np.exp(data['U_3'])) ** (1 / beta[5]) + \\\n",
    "                             data['avail1'] * np.exp(data['U_1']) ** (1 / beta[5]) + \\\n",
    "                             data['avail2'] * np.exp(data['U_2']) ** (1 / beta[5]))\n",
    "    data['log_U_flat_3'] = np.log((alpha_3_with_flat * data['avail3'] * np.exp(data['U_3'])) ** (1 / beta[6]) + \\\n",
    "                            data['avail4'] * np.exp(data['U_4']) ** (1 / beta[6]) + \\\n",
    "                            data['avail5'] * np.exp(data['U_5']) ** (1 / beta[6]))\n",
    "\n",
    "    # Nest probabilities\n",
    "    data['log_P_nest_measured_3'] = data['log_U_measured_3'] * beta[5] - \\\n",
    "                                np.log(np.exp(data['log_U_measured_3']) ** beta[5] + \\\n",
    "                                       np.exp(data['log_U_flat_3']) ** beta[6])\n",
    "    data['log_P_nest_flat_3'] = np.log(1 - np.exp(data['log_P_nest_measured_3']))\n",
    "\n",
    "    # Within nest probabilities\n",
    "    data['log_P_1_in_measured_3'] = np.log(data['avail1']) + data['U_1'] / beta[5] - data['log_U_measured_3']\n",
    "    data['log_P_3_in_measured_3'] = (np.log(data['avail3']) + np.log(alpha_3_with_measured) + \\\n",
    "                                     data['U_3']) / beta[5] - data['log_U_measured_3']\n",
    "    data['log_P_2_in_measured_3'] = np.log(1 - np.exp(data['log_P_1_in_measured_3']) - \\\n",
    "                                           np.exp(data['log_P_3_in_measured_3']))\n",
    "    data['log_P_4_in_flat_3'] = np.where(data['avail4'] == 0, -np.inf,\n",
    "                                     np.log(data['avail4']) + data['U_4'] / beta[6] - data['log_U_flat_3'])\n",
    "    data['log_P_3_in_flat_3'] = (np.log(data['avail3']) + np.log(alpha_3_with_flat) + \\\n",
    "                                 data['U_3']) / beta[6] - data['log_U_flat_3']\n",
    "    data['log_P_5_in_flat_3'] = np.where(data['avail5'] == 0, -np.inf, \n",
    "                                         np.log(1 - np.exp(data['log_P_4_in_flat_3']) - \\\n",
    "                                                np.exp(data['log_P_3_in_flat_3'])))\n",
    "\n",
    "    # Full probabilities\n",
    "    data['P_1'] = np.exp(data['log_P_nest_measured_3'] + data['log_P_1_in_measured_3'])\n",
    "    data['P_2'] = np.exp(data['log_P_nest_measured_3'] + data['log_P_2_in_measured_3'])\n",
    "    data['P_3'] = np.exp(data['log_P_nest_measured_3'] + data['log_P_3_in_measured_3']) + \\\n",
    "                np.exp(data['log_P_nest_flat_3'] + data['log_P_3_in_flat_3'])\n",
    "    data['P_4'] = np.exp(data['log_P_nest_flat_3'] + data['log_P_4_in_flat_3'])\n",
    "    data['P_5'] = np.exp(data['log_P_nest_flat_3'] + data['log_P_5_in_flat_3'])\n",
    "\n",
    "    # Calculate probability for chosen alternative for each row\n",
    "    data['P'] = (data['choice'] == 1) * data['P_1'] + \\\n",
    "                (data['choice'] == 2) * data['P_2'] + \\\n",
    "                (data['choice'] == 3) * data['P_3'] + \\\n",
    "                (data['choice'] == 4) * data['P_4'] + \\\n",
    "                (data['choice'] == 5) * data['P_5']\n",
    "\n",
    "    # Calculate log-likelihood \n",
    "    LL = data['P'].apply(np.log).sum()\n",
    "\n",
    "    return -LL  # We minimize negative log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/telephone.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/telephone.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogcost1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogcost2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/telephone.dat'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('./data/telephone.dat', sep='\\t')\n",
    "\n",
    "data['logcost1'] = np.log(data['cost1'])\n",
    "data['logcost2'] = np.log(data['cost2'])\n",
    "data['logcost3'] = np.log(data['cost3'])\n",
    "data['logcost4'] = np.log(data['cost4'])\n",
    "data['logcost5'] = np.log(data['cost5'])\n",
    "\n",
    "# Define model parameters\n",
    "beta = np.array([0, 0, 0, 0, 0, 1, 1])\n",
    "# lambda_n = 1 / mu_n is a measure of the degree of independence in unobserved utility among\n",
    "# the alternatives in nest n.\n",
    "# It should be between 0 and 1 with lambda_n = 1 indicating full independence.\n",
    "beta_names = [\"ASC_1\", \"ASC_3\", \"ASC_4\", \"ASC_5\", \"BETA_COST\", \"lambda_measured\", \"lambda_flat\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:590: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Results:\n",
      "         Parameter  Estimate  Robust Asymptotic SE  t-statistic       p-value\n",
      "0            ASC_1 -1.635754              0.496645    -3.293610  1.071442e-03\n",
      "1            ASC_3  2.199670              0.556739     3.950990  9.104589e-05\n",
      "2            ASC_4  2.426402              1.316582     1.842956  6.602838e-02\n",
      "3            ASC_5  4.084728              1.053189     3.878438  1.217014e-04\n",
      "4        BETA_COST -3.354164              0.582177    -5.761416  1.598521e-08\n",
      "5  lambda_measured  2.541826              0.624433     4.070612  5.587709e-05\n",
      "6      lambda_flat  1.957885              0.714936     2.738544  6.429389e-03\n",
      "AIC: 961.2124055418653\n",
      "BIC: 989.7237172805682\n"
     ]
    }
   ],
   "source": [
    "# Estimate parameters\n",
    "result, se, t_stat, p_value, aic, bic  = estimate_nested_logit(data, beta, beta_names, log_likelihood_telephone_CNLM2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Applying DIB algorithm </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/16047hxn3hdgt8s5qmq_gnqh0000gp/T/ipykernel_1919/1840364846.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_logcost['probability'] = data_logcost.apply(lambda row: row_counts[tuple(row)] / total_rows, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logcost1</th>\n",
       "      <th>logcost2</th>\n",
       "      <th>logcost3</th>\n",
       "      <th>logcost4</th>\n",
       "      <th>logcost5</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.761300</td>\n",
       "      <td>1.754404</td>\n",
       "      <td>2.545531</td>\n",
       "      <td>13.815511</td>\n",
       "      <td>3.147595</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.258461</td>\n",
       "      <td>1.754404</td>\n",
       "      <td>2.507972</td>\n",
       "      <td>13.815511</td>\n",
       "      <td>3.147595</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.627278</td>\n",
       "      <td>1.754404</td>\n",
       "      <td>2.439735</td>\n",
       "      <td>13.815511</td>\n",
       "      <td>3.342155</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.558145</td>\n",
       "      <td>1.754404</td>\n",
       "      <td>2.347558</td>\n",
       "      <td>13.815511</td>\n",
       "      <td>3.342155</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.145931</td>\n",
       "      <td>1.953028</td>\n",
       "      <td>2.662355</td>\n",
       "      <td>13.815511</td>\n",
       "      <td>3.342155</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logcost1  logcost2  logcost3   logcost4  logcost5  probability\n",
       "0  1.761300  1.754404  2.545531  13.815511  3.147595     0.002304\n",
       "1  1.258461  1.754404  2.507972  13.815511  3.147595     0.002304\n",
       "2  1.627278  1.754404  2.439735  13.815511  3.342155     0.002304\n",
       "3  1.558145  1.754404  2.347558  13.815511  3.342155     0.002304\n",
       "4  2.145931  1.953028  2.662355  13.815511  3.342155     0.002304"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_logcost = data[['logcost1', 'logcost2', 'logcost3', 'logcost4', 'logcost5']]\n",
    "\n",
    "# Function to compare rows with a reference row\n",
    "def count_same_rows(df):\n",
    "    row_counts = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Convert the row to a tuple to make it hashable\n",
    "        row_tuple = tuple(row)\n",
    "        \n",
    "        # Count the occurrences of the row in the dataframe\n",
    "        if row_tuple in row_counts:\n",
    "            row_counts[row_tuple] += 1\n",
    "        else:\n",
    "            row_counts[row_tuple] = 1\n",
    "            \n",
    "    return row_counts\n",
    "\n",
    "# Count occurrences of each row\n",
    "row_counts = count_same_rows(data_logcost)\n",
    "\n",
    "# Add a new column with probabilities\n",
    "total_rows = len(data_logcost)\n",
    "data_logcost['probability'] = data_logcost.apply(lambda row: row_counts[tuple(row)] / total_rows, axis=1)\n",
    "data_logcost.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x = data_logcost['probability'].values\n",
    "p_y_given_x = data[['P_1', 'P_2', 'P_3', 'P_4', 'P_5']].values\n",
    "p_xy = p_x[:, np.newaxis] * p_y_given_x\n",
    "\n",
    "# Normalize p_xy \n",
    "p_xy /= p_xy.sum()\n",
    "\n",
    "# Define epsilon value\n",
    "epsilon = 1e-20\n",
    "\n",
    "# Add epsilon to elements equal to 0\n",
    "p_xy[p_xy == 0] += epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Modified version of the DIB algorithm where the maximum number of clusters is the number of alternatives, not the number of individuals </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_geom_DIB import geom_DIB_on_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 out of 5000\n",
      "Iteration: 2 out of 5000\n",
      "Iteration: 3 out of 5000\n",
      "Iteration: 4 out of 5000\n",
      "Iteration: 5 out of 5000\n",
      "Iteration: 6 out of 5000\n",
      "Iteration: 7 out of 5000\n",
      "Iteration: 8 out of 5000\n",
      "Iteration: 9 out of 5000\n",
      "Iteration: 10 out of 5000\n",
      "Iteration: 11 out of 5000\n"
     ]
    }
   ],
   "source": [
    "q_t_given_x, q_t, q_y_given_t = geom_DIB_on_alternatives(p_xy, beta=5000, max_iter=5000, threshold=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 5\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of clusters\n",
    "column_sum = np.sum(q_t_given_x, axis=0)\n",
    "num_clusters = np.count_nonzero(column_sum)\n",
    "print(\"Number of clusters:\", num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    132\n",
       "3    114\n",
       "1     99\n",
       "2     54\n",
       "4     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column choice_nest which is 1 if choice= 1 or 2, and 2 otherwise\n",
    "data['choice_nest'] = np.where(data['choice'].isin([1, 2]), 1, 2)\n",
    "data['cluster'] = np.argmax(q_t_given_x, axis=1)\n",
    "data['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choice_nest\n",
       "2    238\n",
       "1    196\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['choice_nest'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>choice</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "choice    1   2   3  4   5\n",
       "cluster                   \n",
       "0        21  58  53  0   0\n",
       "1        11  34  40  0  14\n",
       "2         3  10  29  3   9\n",
       "3        37  20  52  0   5\n",
       "4         1   1   4  0  29"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of each alternative 1, 2, 3, 4, 5 in each cluster \n",
    "cluster_counts = data.groupby(['cluster', 'choice']).size().unstack(fill_value=0)\n",
    "cluster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>max_proba</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "max_proba   1   2    3  4   5\n",
       "cluster                      \n",
       "0           0   0  132  0   0\n",
       "1           0  56   43  0   0\n",
       "2           0   0   43  2   9\n",
       "3          21  35   58  0   0\n",
       "4           0   0    0  0  35"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['max_proba'] = data[['P_1', 'P_2', 'P_3', 'P_4', 'P_5']].idxmax(axis=1).str[-1].astype(int)\n",
    "cluster_counts2 = data.groupby(['cluster', 'max_proba']).size().unstack(fill_value=0)\n",
    "cluster_counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>simulated_choice</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "simulated_choice   1   2   3  4   5\n",
       "cluster                            \n",
       "0                 19  41  72  0   0\n",
       "1                 13  39  38  0   9\n",
       "2                  4  11  24  5  10\n",
       "3                 27  41  42  0   4\n",
       "4                  1   1   9  1  23"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['simulated_choice'] = data.apply(simulate_choice, axis=1)\n",
    "cluster_counts3 = data.groupby(['cluster', 'simulated_choice']).size().unstack(fill_value=0)\n",
    "cluster_counts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betas = np.linspace(0, 50, 51)\n",
    "# # Initialize an empty list to store the number of clusters\n",
    "# num_clusters_list = []\n",
    "\n",
    "# # Iterate over each beta value\n",
    "# for beta in betas:\n",
    "#     # Run iterative_algorithm to obtain q_t_given_x\n",
    "#     q_t_given_x, _, _ = geom_DIB_on_alternatives(p_xy, max_iter=5000, beta=beta, threshold=1e-4)\n",
    "    \n",
    "#     # Calculate the number of clusters\n",
    "#     column_sum = np.sum(q_t_given_x, axis=0)\n",
    "#     num_clusters = np.count_nonzero(column_sum)\n",
    "    \n",
    "#     # Append the number of clusters to the list\n",
    "#     num_clusters_list.append(num_clusters)\n",
    "\n",
    "# # Plot the number of clusters against beta values\n",
    "# plt.plot(betas, num_clusters_list)\n",
    "# plt.xlabel('Beta')\n",
    "# plt.ylabel('Number of Clusters')\n",
    "# plt.title('Number of Clusters vs. Beta')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
